{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-04-04_23-58-51'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task1_train import *\n",
    "from hparams import hparams, DEVICE_DICT, CITY_DICT, SCENE_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ==== Display hparams ====         \n",
      "\n",
      "                  fs | 44100               \n",
      "           nsc_in_ms | 200                 \n",
      "        mel_band_num | 80                  \n",
      "           nov_in_ms | 100                 \n",
      "                 nsc | 8820                \n",
      "                 nov | 4410                \n",
      "           max_epoch | 2                   \n",
      "          batch_size | 16                  \n",
      "\n",
      "[ Loaded datasets/TAU-urban-acoustic-scenes-2020-mobile-development/evaluation_setup/fold1_train.csv ] [ Length: 13965 ]\n",
      "[ Loaded datasets/TAU-urban-acoustic-scenes-2020-mobile-development/evaluation_setup/fold1_evaluate.csv ] [ Length: 2970 ]\n",
      "[ FileInfo(file_path='datasets/TAU-urban-acoustic-scenes-2020-mobile-development/audio/airport-lisbon-1000-40000-a.wav', city='lisbon', device='a', scene='airport'), ..., FileInfo(file_path='datasets/TAU-urban-acoustic-scenes-2020-mobile-development/audio/tram-lyon-1112-41171-s3.wav', city='lyon', device='s3', scene='tram') ]\n"
     ]
    }
   ],
   "source": [
    "print('{:^43s}'.format('==== Display hparams ===='))\n",
    "\n",
    "display_dict(hparams)\n",
    "\n",
    "dataset_name = 'TAU-urban-acoustic-scenes-2020-mobile-development'\n",
    "\n",
    "dataset_base_path = os.path.join('datasets', dataset_name)\n",
    "\n",
    "metadata_train_path = dataset_base_path + '/' + 'evaluation_setup' + '/' + 'fold1_train.csv'\n",
    "\n",
    "# metadata_test_path = 'datasets/' + dataset_name + '/' + 'evaluation_setup' + '/' + 'fold1_test.csv' \n",
    "\n",
    "metadata_eval_path = dataset_base_path + '/' + 'evaluation_setup' + '/' + 'fold1_evaluate.csv' \n",
    "\n",
    "metadata_train = load_metadata(metadata_train_path, dataset_base_path)\n",
    "\n",
    "# metadata_test = load_metadata(metadata_path=metadata_test_path)\n",
    "\n",
    "metadata_eval = load_metadata(metadata_eval_path, dataset_base_path)\n",
    "\n",
    "train_dataset_loader = DatasetLoader(metadata_train)\n",
    "eval_dataset_loader = DatasetLoader(metadata_eval)\n",
    "\n",
    "print(train_dataset_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FileInfo(file_path='datasets/TAU-urban-acoustic-scenes-2020-mobile-development/audio/street_pedestrian-stockholm-157-4755-a.wav', city='stockholm', device='a', scene='street_pedestrian'),\n",
       " FileInfo(file_path='datasets/TAU-urban-acoustic-scenes-2020-mobile-development/audio/shopping_mall-stockholm-136-4116-a.wav', city='stockholm', device='a', scene='shopping_mall'),\n",
       " FileInfo(file_path='datasets/TAU-urban-acoustic-scenes-2020-mobile-development/audio/public_square-stockholm-120-3544-a.wav', city='stockholm', device='a', scene='public_square'),\n",
       " FileInfo(file_path='datasets/TAU-urban-acoustic-scenes-2020-mobile-development/audio/airport-barcelona-1-75-a.wav', city='barcelona', device='a', scene='airport'),\n",
       " FileInfo(file_path='datasets/TAU-urban-acoustic-scenes-2020-mobile-development/audio/street_pedestrian-london-149-4530-a.wav', city='london', device='a', scene='street_pedestrian'),\n",
       " FileInfo(file_path='datasets/TAU-urban-acoustic-scenes-2020-mobile-development/audio/bus-prague-1032-42940-s3.wav', city='prague', device='s3', scene='bus'),\n",
       " FileInfo(file_path='datasets/TAU-urban-acoustic-scenes-2020-mobile-development/audio/metro_station-milan-1050-42635-s3.wav', city='milan', device='s3', scene='metro_station'),\n",
       " FileInfo(file_path='datasets/TAU-urban-acoustic-scenes-2020-mobile-development/audio/metro_station-helsinki-64-1924-a.wav', city='helsinki', device='a', scene='metro_station'),\n",
       " FileInfo(file_path='datasets/TAU-urban-acoustic-scenes-2020-mobile-development/audio/street_pedestrian-barcelona-144-4352-a.wav', city='barcelona', device='a', scene='street_pedestrian'),\n",
       " FileInfo(file_path='datasets/TAU-urban-acoustic-scenes-2020-mobile-development/audio/street_traffic-helsinki-166-5103-a.wav', city='helsinki', device='a', scene='street_traffic')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(metadata_train)\n",
    "metadata_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Start Loading ]\n"
     ]
    }
   ],
   "source": [
    "train_dataset_loader.start_loading()\n",
    "for batch in train_dataset_loader.generator():\n",
    "    mel_spectrogram_batch, file_path_list, city_label, device_label, scene_label = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\ninputs, labels = data\\n\\n# 변화도(Gradient) 매개변수를 0으로 만들고\\noptimizer.zero_grad()\\n\\n# 순전파 + 역전파 + 최적화를 한 후\\noutputs = net(inputs)\\nloss = criterion(outputs, labels)\\nloss.backward()\\noptimizer.step()\\n\\n# 통계를 출력합니다.\\nrunning_loss += loss.item()\\nif i % 2000 == 1999:    # print every 2000 mini-batches\\n    print('[%d, %5d] loss: %.3f' %\\n          (epoch + 1, i + 1, running_loss / 2000))\\n    running_loss = 0.0\\n    \\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "inputs, labels = data\n",
    "\n",
    "# 변화도(Gradient) 매개변수를 0으로 만들고\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# 순전파 + 역전파 + 최적화를 한 후\n",
    "outputs = net(inputs)\n",
    "loss = criterion(outputs, labels)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# 통계를 출력합니다.\n",
    "running_loss += loss.item()\n",
    "if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "    print('[%d, %5d] loss: %.3f' %\n",
    "          (epoch + 1, i + 1, running_loss / 2000))\n",
    "    running_loss = 0.0\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "class CRNN_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CRNN_Net, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 256, kernel_size=(80, 11), stride=5)\n",
    "        self.rnn_1 = nn.RNN(256, 256)\n",
    "        self.rnn_2 = nn.RNN(256, 128)\n",
    "#         self.rnn_3 = nn.RNN(128, 64)\n",
    "#         self.rnn_4 = nn.RNN(64, 32)\n",
    "        self.fc = nn.Linear(128 * 19, len(SCENE_DICT))\n",
    "        \n",
    "        # (B, M[80], H[1], T[101]) => (B, M[80], H[256], T[21])\n",
    "        \n",
    "\n",
    "    def forward(self, tensor):\n",
    "        tensor = torch.Tensor(tensor).unsqueeze(1)\n",
    "        tensor = F.relu(self.conv(tensor))\n",
    "        tensor = tensor.squeeze(2)\n",
    "        tensor = tensor.permute(2, 0, 1) # (B, H, T) => (T, B, H)\n",
    "        tensor, _ = self.rnn_1(tensor)\n",
    "        tensor, _ = self.rnn_2(tensor)\n",
    "#         tensor, _ = self.rnn_3(tensor)\n",
    "#         tensor, _ = self.rnn_4(tensor)\n",
    "        tensor = tensor.permute(1, 2, 0) # (T, B, H) => (B, H, T)\n",
    "#         tensor = tensor.permute()\n",
    "        tensor = tensor.reshape(tensor.shape[0], -1)\n",
    "\n",
    "        tensor = self.fc(tensor)\n",
    "        tensor = F.log_softmax(tensor, dim=-1)\n",
    "\n",
    "        return tensor\n",
    "\n",
    "net = CRNN_Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(batch[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_borealis)",
   "language": "python",
   "name": "conda_borealis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
